{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='kEhYJJanyud3jQ',\n",
    "                     client_secret='k81gCR33nRsHd1CkkRhM3lqAGzw',\n",
    "                     password='Annie62595',\n",
    "                     user_agent='testscript by /u/peterz36',\n",
    "                     username='peterz36')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       title  score      id   subreddit  \\\n",
      "0                             I'm struggling      1  g4iqh9  depression   \n",
      "1                           I hate waking up      3  g4iq4a  depression   \n",
      "2             I don't enjoy anything anymore      4  g4ipu3  depression   \n",
      "3                            Who I've become      1  g4ipl3  depression   \n",
      "4                       Kids with depression      2  g4ipic  depression   \n",
      "..                                       ...    ...     ...         ...   \n",
      "995                     What would u choose?      3  g3bea1  depression   \n",
      "996                   I cant force out tears      3  g3bdzx  depression   \n",
      "997          Quit prozac my mother disagrees      4  g3bdqe  depression   \n",
      "998  People think that depression is sadness      5  g3bcgb  depression   \n",
      "999                   someone wants to chat.      2  g3bb9t  depression   \n",
      "\n",
      "                                                   url  num_comments  \\\n",
      "0    https://www.reddit.com/r/depression/comments/g...             0   \n",
      "1    https://www.reddit.com/r/depression/comments/g...             0   \n",
      "2    https://www.reddit.com/r/depression/comments/g...             0   \n",
      "3    https://www.reddit.com/r/depression/comments/g...             0   \n",
      "4    https://www.reddit.com/r/depression/comments/g...             0   \n",
      "..                                                 ...           ...   \n",
      "995  https://www.reddit.com/r/depression/comments/g...             2   \n",
      "996  https://www.reddit.com/r/depression/comments/g...             6   \n",
      "997  https://www.reddit.com/r/depression/comments/g...             1   \n",
      "998  https://www.reddit.com/r/depression/comments/g...             0   \n",
      "999  https://www.reddit.com/r/depression/comments/g...             1   \n",
      "\n",
      "                                                  body       created  \\\n",
      "0    I try so hard, every day. I try to live, to be...  1.587371e+09   \n",
      "1    Everyday I wake up and as soon as I open my ey...  1.587371e+09   \n",
      "2    I've been struggling on and off for over a yea...  1.587371e+09   \n",
      "3    It's gotten harder and harder for me to even a...  1.587371e+09   \n",
      "4    Kids with depression\\n\\nHi all! I need some ad...  1.587371e+09   \n",
      "..                                                 ...           ...   \n",
      "995  Saw a post on the internet, and my thoughts we...  1.587189e+09   \n",
      "996  I just want to let my emotions out but I cant ...  1.587189e+09   \n",
      "997  I quit prozac two weeks ago due to the lockdow...  1.587189e+09   \n",
      "998  I have depression. and I wont pretend that my ...  1.587189e+09   \n",
      "999  i'm friendless and thinking of ending it today...  1.587189e+09   \n",
      "\n",
      "                   user  \n",
      "0           nonrealexis  \n",
      "1            blagreddit  \n",
      "2             NuttyMate  \n",
      "3              JimRatte  \n",
      "4            futurenp97  \n",
      "..                  ...  \n",
      "995            Mazurroo  \n",
      "996    rose_among_bones  \n",
      "997        Felixescobar  \n",
      "998   Pedantic_Porpoise  \n",
      "999  Regular-Permission  \n",
      "\n",
      "[1000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "posts = []\n",
    "ml_subreddit = reddit.subreddit('depression')\n",
    "for post in ml_subreddit.new(limit=1000):\n",
    "    posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created, post.author])\n",
    "posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created', 'user'])\n",
    "print(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_users = posts.user\n",
    "d_karma = []\n",
    "for user in d_users:\n",
    "   try:\n",
    "    d_karma.append(reddit.redditor(user).comment_karma)\n",
    "   except:\n",
    "    d_karma.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Users</th>\n",
       "      <th>Karma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nonrealexis</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>JimRatte</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>paloofthesanto</td>\n",
       "      <td>2665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>SelectOperator7</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Toriun</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>Mazurroo</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>rose_among_bones</td>\n",
       "      <td>14703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>Felixescobar</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>Pedantic_Porpoise</td>\n",
       "      <td>7871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>Regular-Permission</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Users  Karma\n",
       "0           nonrealexis    237\n",
       "3              JimRatte    214\n",
       "7        paloofthesanto   2665\n",
       "8       SelectOperator7    137\n",
       "11               Toriun    219\n",
       "..                  ...    ...\n",
       "995            Mazurroo    946\n",
       "996    rose_among_bones  14703\n",
       "997        Felixescobar    253\n",
       "998   Pedantic_Porpoise   7871\n",
       "999  Regular-Permission    127\n",
       "\n",
       "[440 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df = pd.DataFrame({'Users': d_users, 'Karma': d_karma})\n",
    "users_filtered = user_df[user_df[\"Karma\"] > 100]\n",
    "users_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "from contraction_list import CONTRACTION_MAP\n",
    "def replace_contractions(text):\n",
    "    \"\"\"Replace contractions in string of text\"\"\"\n",
    "    return contractions.fix(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = pd.read_csv(\"Depression_related.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = remove_list.Subreddits.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting all posts (that we can) for each d_user\n",
    "d_posts = []\n",
    "for user in users_filtered[\"Users\"]:\n",
    "    sample_text = ''\n",
    "    subtext = ''\n",
    "    for submission in reddit.redditor(str(user)).submissions.new(limit=1000):\n",
    "        if submission.subreddit in remove_list:\n",
    "            continue \n",
    "        try: \n",
    "            entry = \" \".join([submission.title, submission.selftext])\n",
    "            entry = replace_contractions(entry)\n",
    "            sample_text += entry\n",
    "        except: \n",
    "            pass\n",
    "    d_posts.append(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_frame = pd.DataFrame(d_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I am angry My dad passed away almost 9 months ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AITA or just not good at caring? [removed]ELI5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sorry for the cross post. The shows and books ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I just need speak to someone privately please....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Getting an error on Brove/Chrome browser then ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>I hate... [removed]This suggest option makes m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>436</td>\n",
       "      <td>Upto no good I presume Is the composition okay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>437</td>\n",
       "      <td>Not Buying Anymore [removed]Should I quit vapi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438</td>\n",
       "      <td>Computer will not boot past windows logo. Vide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439</td>\n",
       "      <td>I fit the PTSD criteria. I know how self-diagn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0    I am angry My dad passed away almost 9 months ...\n",
       "1    AITA or just not good at caring? [removed]ELI5...\n",
       "2    Sorry for the cross post. The shows and books ...\n",
       "3    I just need speak to someone privately please....\n",
       "4    Getting an error on Brove/Chrome browser then ...\n",
       "..                                                 ...\n",
       "435  I hate... [removed]This suggest option makes m...\n",
       "436  Upto no good I presume Is the composition okay...\n",
       "437  Not Buying Anymore [removed]Should I quit vapi...\n",
       "438  Computer will not boot past windows logo. Vide...\n",
       "439  I fit the PTSD criteria. I know how self-diagn...\n",
       "\n",
       "[440 rows x 1 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "posts = []\n",
    "ml_subreddit = reddit.subreddit('AskReddit')\n",
    "for post in ml_subreddit.new(limit=1000):\n",
    "    posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created, post.author])\n",
    "posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created', 'user'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_users = posts.user\n",
    "c_karma = []\n",
    "for user in c_users:\n",
    "   try:\n",
    "    c_karma.append(reddit.redditor(user).comment_karma)\n",
    "   except:\n",
    "    c_karma.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Users</th>\n",
       "      <th>Karma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mets4Ever2k</td>\n",
       "      <td>4662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>wildluciddreaming</td>\n",
       "      <td>1819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>tom_is_the_bomb</td>\n",
       "      <td>3903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-tushar-</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>shivam111111</td>\n",
       "      <td>13988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>stinkydongman</td>\n",
       "      <td>5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>971</td>\n",
       "      <td>King_Abalam</td>\n",
       "      <td>46445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>972</td>\n",
       "      <td>JudgeBergan</td>\n",
       "      <td>1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>974</td>\n",
       "      <td>RandoBrandoBanjo</td>\n",
       "      <td>8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>976</td>\n",
       "      <td>HolzwurmHolz</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>664 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Users  Karma\n",
       "0          Mets4Ever2k   4662\n",
       "1    wildluciddreaming   1819\n",
       "2      tom_is_the_bomb   3903\n",
       "3             -tushar-    678\n",
       "6         shivam111111  13988\n",
       "..                 ...    ...\n",
       "970      stinkydongman   5255\n",
       "971        King_Abalam  46445\n",
       "972        JudgeBergan   1107\n",
       "974   RandoBrandoBanjo   8640\n",
       "976       HolzwurmHolz    161\n",
       "\n",
       "[664 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_user_df = pd.DataFrame({'Users': c_users, 'Karma': c_karma})\n",
    "c_users_filtered = c_user_df[c_user_df[\"Karma\"] > 100]\n",
    "c_users_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_posts = []\n",
    "for user in users_filtered[\"Users\"]:\n",
    "    sample_text = ''\n",
    "    subtext = ''\n",
    "    for submission in reddit.redditor(str(user)).submissions.new(limit=1000):\n",
    "        if submission.subreddit in remove_list:\n",
    "            continue \n",
    "        try: \n",
    "            entry = \" \".join([submission.title, submission.selftext])\n",
    "            entry = replace_contractions(entry)\n",
    "            sample_text += entry\n",
    "        except: \n",
    "            pass\n",
    "    c_posts.append(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, string\n",
    "import nltk\n",
    "import inflect\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import spacy\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes all punctuations, html stuff, numbers (changes them to words), stop words (a, and, the, etc...),\n",
    "#and then finds the stem of each words (combines words like run and running into one)\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in words:\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return stems\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_posts = stem_words(d_posts)\n",
    "d_normalized_posts = normalize(d_posts)\n",
    "c_posts = stem_words(c_posts)\n",
    "c_normalized_posts = normalize(c_posts)\n",
    "Depressed = pd.DataFrame({'Text': d_normalized_posts, 'Category': \"Depressed\"})\n",
    "Control = pd.DataFrame({'Text': c_normalized_posts, 'Category': \"Control\"})\n",
    "Full = pd.concat([Depressed, Control])\n",
    "Full = Full.sample(frac=1)\n",
    "Full = Full.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full.to_csv(\"reddit_data_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>anyone had an issue of high rating sugar spike...</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>seeing people late on pc my ping is normal and...</td>\n",
       "      <td>Depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>there is absolutely no reason for the sims 4 c...</td>\n",
       "      <td>Depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>do any of you guys have the yubo app removeddo...</td>\n",
       "      <td>Depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>hi  i need help  i atarted watching naruto  th...</td>\n",
       "      <td>Depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>855</td>\n",
       "      <td>sweats ruin the game removedfix sbmm please re...</td>\n",
       "      <td>Depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>856</td>\n",
       "      <td>to the people with gtx 1060 3gbs you can do it...</td>\n",
       "      <td>Depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>857</td>\n",
       "      <td>i went to walmart yesterday i had to wear a ma...</td>\n",
       "      <td>Depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>858</td>\n",
       "      <td>how do i cope with becoming uglier i just turn...</td>\n",
       "      <td>Depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>859</td>\n",
       "      <td>what is the best way to cope with the thought ...</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>860 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text   Category\n",
       "0    anyone had an issue of high rating sugar spike...    Control\n",
       "1    seeing people late on pc my ping is normal and...  Depressed\n",
       "2    there is absolutely no reason for the sims 4 c...  Depressed\n",
       "3    do any of you guys have the yubo app removeddo...  Depressed\n",
       "4    hi  i need help  i atarted watching naruto  th...  Depressed\n",
       "..                                                 ...        ...\n",
       "855  sweats ruin the game removedfix sbmm please re...  Depressed\n",
       "856  to the people with gtx 1060 3gbs you can do it...  Depressed\n",
       "857  i went to walmart yesterday i had to wear a ma...  Depressed\n",
       "858  how do i cope with becoming uglier i just turn...  Depressed\n",
       "859  what is the best way to cope with the thought ...    Control\n",
       "\n",
       "[860 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
